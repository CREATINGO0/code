the idea of mergeSortSC is that if the length of
the subfile is longer than the threshold then we
will recursively sort that through mergesort and
once it get shorter we will change to insertion-
sort. the threshold is defined through macro
#define.

the accuracy test is done by ranking one file
generated by genRandom with mergeSortSC and
mergeSort and diff those two results. it turned
out that they have no differences, which means
that mergeSortSC is generating the correct rank
of the list.

as for the performance test, to make the gap
obvious, a file of 100k random numbers is made.
the time is an average of three tests. the
results are as follows:

pivot	time
2[1]	0.136s
5		0.130s
10		0.137s
15		0.132s
20		0.135s
25		0.131s
50		0.124s
100		0.130s
200		0.143s

[1]: exactly the original mergesort

the gap of pivot from 2 to 25 are too slight so
they do not make any sense; however it looks
like a convex curve when tested with large ones
like 100 and 200.

this may come from that mergesort is suitable
for large scale of data while insertion works
better for small ones. so feeding mergesort with
too short subfiles or insertion too long may
slow down its performance. a proper pivot shall
make the combination considerably efficient.
